{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0565cdb",
   "metadata": {},
   "source": [
    "## Spring 2024 Info Session LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a81429",
   "metadata": {},
   "source": [
    "Transcribing MP4 File of Info Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfc6fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
      "\u001b[K     |████████████████████████████████| 800 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: more-itertools in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from openai-whisper) (8.7.0)\n",
      "Requirement already satisfied: numpy in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from openai-whisper) (1.23.5)\n",
      "Requirement already satisfied: numba in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from openai-whisper) (0.53.1)\n",
      "Requirement already satisfied: tiktoken in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from openai-whisper) (0.7.0)\n",
      "Requirement already satisfied: torch in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from openai-whisper) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from numba->openai-whisper) (0.36.0)\n",
      "Requirement already satisfied: setuptools in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from numba->openai-whisper) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from tiktoken->openai-whisper) (2023.12.25)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from torch->openai-whisper) (1.8)\n",
      "Requirement already satisfied: typing-extensions in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from torch->openai-whisper) (3.0.12)\n",
      "Requirement already satisfied: networkx in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from torch->openai-whisper) (2.5)\n",
      "Requirement already satisfied: jinja2 in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from torch->openai-whisper) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from jinja2->torch->openai-whisper) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from networkx->torch->openai-whisper) (5.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from sympy->torch->openai-whisper) (1.2.1)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803319 sha256=efe6068d6d8bc66cdcac460ba519ddeb420c773cebbd9d4e272cc4da4990932d\n",
      "  Stored in directory: /Users/justingong/Library/Caches/pip/wheels/58/9f/3f/657caca5c67b43cb90d168c2061936f3255bc28fef73b752ea\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: openai-whisper\n",
      "Successfully installed openai-whisper-20240930\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32046a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg-python\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: future in /Users/justingong/opt/anaconda3/lib/python3.8/site-packages (from ffmpeg-python) (0.18.2)\n",
      "Installing collected packages: ffmpeg-python\n",
      "Successfully installed ffmpeg-python-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918911df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justingong/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from whisper import load_model\n",
    "\n",
    "# Load Whisper model\n",
    "model = load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98bc8768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justingong/opt/anaconda3/lib/python3.8/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bf5616f7b41a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spring2024_info_session.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Pad 30-seconds of silence to the input audio, for slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_mel_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_SAMPLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0mcontent_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mN_FRAMES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mcontent_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_frames\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mHOP_LENGTH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mSAMPLE_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/whisper/audio.py\u001b[0m in \u001b[0;36mlog_mel_spectrogram\u001b[0;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/whisper/audio.py\u001b[0m in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# fmt: on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to load audio: {e.stderr.decode()}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    856\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    859\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffmpeg'"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(\"spring2024_info_session.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"spring2024_info_session.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a19304c",
   "metadata": {},
   "source": [
    "**Cleaning Transcription and Converting into PDF Format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72dddbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "import re\n",
    "\n",
    "with open(\"spring2024_info_session.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "cleaned_text = re.sub(r'\\b(uh|um)\\b', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "pdf = FPDF()\n",
    "pdf.set_auto_page_break(auto=True, margin=15)\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "pdf.multi_cell(0, 10, cleaned_text)\n",
    "pdf.output(\"spring2024_info_session_transcript.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eca7f4",
   "metadata": {},
   "source": [
    "**Loading in Transcription in LangChain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f12ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = 'REDACTED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7874ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"spring2024_info_session_transcript.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70c7e22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'spring2024_info_session_transcript.pdf', 'page': 0}, page_content=\"Okay, awesome.\\nAnd yeah, let's just jump right into it.\\nSo my name is Vade, I'm the president of the Data Science Union.\\nAnd during this info session, we're just going to be taking you through a couple of things.\\nFirst, you're going to meet us, the board.\\nAnd we'll give you a little bit of insight into, you know,\\nwhat major we are, like what we do for DSU.\\nWe'll tell you a little bit about our organization and our core pillars and mission.\\nAnd then we'll get into a little bit of what we offer as well as our recruitment process.\\nAnd then at 7 p.m., we will have time to answer any and all questions.\\nSo I'm going to hand it off now.\\nTwo.\\nOh, there's me.\\nI'm the president.\\nAnd then next we have Justin.\\nHi, everyone.\\nMy name is Justin.\\nI'm the internal vice president here at DSU.\\nAnd I am a data theory major.\\nHi, everyone.\\nMy name is ball.\\nI'm a third year data theory major.\\nAnd I'm the external vice president of DC.\\nHi, everyone.\\nI'm Jacob.\\nI'm one of the curriculum directors for DSU.\\nAnd I'm a second year data theory major.\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting Pages Information\n",
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae717e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'spring2024_info_session_transcript.pdf', 'page': 1}, page_content=\"Hi, my name is Caleb.\\nAnd I'm a second year data theory major also.\\nAnd I'm finance director.\\nHi, I'm Sonia.\\nI'm also a second year data theory major.\\nAnd I'm the director of marketing.\\nHi, I'm Riley.\\nI'm a second year math of comp major.\\nAnd I'm the client relations director.\\nHi, everyone.\\nI'm Danelle.\\nI'm a third year data theory major.\\nAnd I am the director of professional development.\\nHi, I'm Hannah.\\nI'm a second year stats and data science major.\\nAnd I'm the project director.\\nHey guys, I'm Charlie.\\nI'm a second year stats DS major.\\nAnd I'm director of membership.\\nHey, everyone.\\nLet's get to see all your guys' faces.\\nI'm Daniel.\\nI'm a third year data theory major.\\nAnd I'm running some fun research projects here this year.\\nHi, I'm Maddie.\\nI'm a third year stats major.\\nAnd I'm one of the executive advisors.\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad41e702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8eb091e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, awesome.\\nAnd yeah, let's just jump right into it.\\nSo my name is Vade, I'm the president of the Data Science Union.\\nAnd during this info session, we're just going to be taking you through a couple of things.\\nFirst, you're going to meet us, the board.\\nAnd we'll give you a little bit of insight into, you know,\\nwhat major we are, like what we do for DSU.\\nWe'll tell you a little bit about our organization and our core pillars and mission.\\nAnd then we'll get into a little bit of what we offer as\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b12f9ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'spring2024_info_session_transcript.pdf', 'page': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbc936",
   "metadata": {},
   "source": [
    "**Document Splitting for Meaningful Chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2af66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91c6ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=75,\n",
    "    length_function = len, \n",
    "    separators = [\"\\n\", \". \", \" \"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d21c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = r_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae46dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5afcee8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a7bb2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'spring2024_info_session_transcript.pdf', 'page': 0}, page_content=\"Okay, awesome.\\nAnd yeah, let's just jump right into it.\\nSo my name is Vade, I'm the president of the Data Science Union.\\nAnd during this info session, we're just going to be taking you through a couple of things.\\nFirst, you're going to meet us, the board.\\nAnd we'll give you a little bit of insight into, you know,\\nwhat major we are, like what we do for DSU.\\nWe'll tell you a little bit about our organization and our core pillars and mission.\\nAnd then we'll get into a little bit of what we offer as well as our recruitment process.\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6168ba82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'spring2024_info_session_transcript.pdf', 'page': 0}, page_content=\"And then at 7 p.m., we will have time to answer any and all questions.\\nSo I'm going to hand it off now.\\nTwo.\\nOh, there's me.\\nI'm the president.\\nAnd then next we have Justin.\\nHi, everyone.\\nMy name is Justin.\\nI'm the internal vice president here at DSU.\\nAnd I am a data theory major.\\nHi, everyone.\\nMy name is ball.\\nI'm a third year data theory major.\\nAnd I'm the external vice president of DC.\\nHi, everyone.\\nI'm Jacob.\\nI'm one of the curriculum directors for DSU.\\nAnd I'm a second year data theory major.\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7358d1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'spring2024_info_session_transcript.pdf', 'page': 1}, page_content=\"Hi, my name is Caleb.\\nAnd I'm a second year data theory major also.\\nAnd I'm finance director.\\nHi, I'm Sonia.\\nI'm also a second year data theory major.\\nAnd I'm the director of marketing.\\nHi, I'm Riley.\\nI'm a second year math of comp major.\\nAnd I'm the client relations director.\\nHi, everyone.\\nI'm Danelle.\\nI'm a third year data theory major.\\nAnd I am the director of professional development.\\nHi, I'm Hannah.\\nI'm a second year stats and data science major.\\nAnd I'm the project director.\\nHey guys, I'm Charlie.\\nI'm a second year stats DS major.\\nAnd I'm director of membership.\\nHey, everyone.\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a2f6d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'spring2024_info_session_transcript.pdf', 'page': 13}, page_content=\"technical section. We won't have you code anything. It's more just to test like your critical thinking\\nskills and see how you solve problems, but we really recommend just like talking through your entire\\nthought process.\\nAnd if you want to use any stats knowledge that you do have, then feel free to do so. But yeah, but\\ndon't be nervous. I know it's easier said than done, but we are rooting for you on the other side and\\nwe really just want to get to know you. So yeah.\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[52]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383fdab3",
   "metadata": {},
   "source": [
    "## Embeddings and Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3b2c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3df4c4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-df19ea013e3f>:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en\")\n",
      "/Users/justingong/opt/anaconda3/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/justingong/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f05dd580",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'info_session_vectorstore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c857f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ca55133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-7e22d4d4ada8>:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "vectordb.persist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45148be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do I succeed in coffee chats?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ebcd520",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85cc002e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 13, 'source': 'spring2024_info_session_transcript.pdf'}, page_content=\"place on Saturday morning and afternoon.\\nSo coffee chats or more of a casual conversation just to get to know each of you and also to see\\nhow you work with other people.\\nAnd I know somebody it touched on a lot of our advice, but yeah, our advice this round and along\\nwith honestly all the other rounds is just to be yourself. I know it's cliche, but we really do just want to\\nget to know you. So if it helps you to practice talking about your past experiences, then we definitely\\nrecommend doing that.\")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87c73978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 13, 'source': 'spring2024_info_session_transcript.pdf'}, page_content=\"recommend doing that.\\nAnd we also like to see when you can build off other people's ideas so that your collapse so we can\\nsee that you can collaborate and we can see how you work and interact with others.\\nSo that's coffee chats and then next slide.\\nYeah, then after coffee chats will invite some of you to join us for individual interviews and for this\\nyou can also just casually because again our goal is just to get to know you individually and to\\nunderstand your thought process.\\nSo in the interviews, there will be both a behavioral and a technical section and don't worry for the\")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6397fde",
   "metadata": {},
   "source": [
    "## Loading in Vector Database for Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd4ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec459d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-35267f57ec75>:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embedding = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en\")\n",
      "/Users/justingong/opt/anaconda3/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/justingong/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/justingong/opt/anaconda3/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/justingong/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "<ipython-input-1-35267f57ec75>:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "persist_directory = 'info_session_vectorstore'\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en\")\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee41af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58c014d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I succeed in coffee chats?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9297a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 13, 'source': 'spring2024_info_session_transcript.pdf'}, page_content=\"place on Saturday morning and afternoon.\\nSo coffee chats or more of a casual conversation just to get to know each of you and also to see\\nhow you work with other people.\\nAnd I know somebody it touched on a lot of our advice, but yeah, our advice this round and along\\nwith honestly all the other rounds is just to be yourself. I know it's cliche, but we really do just want to\\nget to know you. So if it helps you to practice talking about your past experiences, then we definitely\\nrecommend doing that.\"),\n",
       " Document(metadata={'page': 10, 'source': 'spring2024_info_session_transcript.pdf'}, page_content=\"And whether it's through our takeovers or just like word of mouth, you've probably just heard how\\nimportant community is for us.\\nIt's something that is really important to get our members tight knit and just to get to know one\\nanother is through programs like we have like a big little program. We run coffee chats.\\nWe have a lot of people such as like retreats, gatherings, like beach socials, like path like recently\\nwe started doing like I am sports together, which I know it's like data scientists doing like I am sports\\ntogether.\"),\n",
       " Document(metadata={'page': 13, 'source': 'spring2024_info_session_transcript.pdf'}, page_content=\"experiences when you're talking about yourself and why DSU and your resume and tie what you\\nlearned in your like past high school experiences or college experiences into tangible skills that you\\ncan bring to our club.\\nAgain, we're just looking for someone who can add to our community and whose eager to learn and\\neager to engage with our social aspects.\\nYeah, so yeah, so looking ahead like mentioned earlier applications will be due this Thursday night\\nand then sometime on Friday will contact some of you to invite you to coffee chat, which will take\\nplace on Saturday morning and afternoon.\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa497868",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = 'REDACTED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d37c29f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-6b82c0377a20>:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  llm = ChatOpenAI(model_name=llm_name, temperature=0, openai_api_key = openai.api_key)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "llm_name = \"gpt-3.5-turbo\" # Can used more advanced model, but for our this should be sufficient\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0, openai_api_key = openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82bd0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, say I don't have enough information to answer the question. \n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "Context: {context}\n",
    "Question: {question}\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a88e6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21ddadf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-cacf0940bb86>:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I succeed in coffee chats?\"\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23171b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To succeed in coffee chats, it is important to be yourself, practice talking about your past experiences, and be able to build off of other people's ideas to show collaboration skills. Additionally, be prepared to discuss your experiences and tie them into tangible skills that you can bring to the club. Showing eagerness to learn and engage with the social aspects of the club is also important. Thanks for asking!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f757e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question): \n",
    "    result = qa_chain({\"query\": question})\n",
    "    print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba235ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The application deadline is this Thursday at midnight. Some applicants will be contacted on Friday for coffee chats on Saturday. Interviews will take place from Monday to Tuesday, with emails sent out to successful applicants by Tuesday night. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"What is the application timeline for this quarter?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b618ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Justin led a project last quarter called the automated resume screener. His team used natural language processing to analyze thousands of resumes and extract important features. They built a clustering model using unsupervised learning to filter the resumes and selected one cluster based on performance. The project also included visualizations of the data, such as separating words in accounting resumes. It was a great learning experience for Justin and his team members. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"Can you give me a brief overview of the resume screener project by Justin?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cda5efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second quarter curriculum is a lot more independent, where you get to pick and work on a project that interests you. You will get to do the complete project from data collection to data cleaning to modeling. You will also be paired up with mentors from DSU to guide you. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"Can you tell me what the second quarter curriculum is?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bbbcbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The four core pillars of DSU are a proprietary curriculum, workshops to prepare for projects, internal and external projects, and a community of data scientists. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"What are DSU's four core pillars?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43b85e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
